# Benchmarks 基准测试

每个查询引擎在性能、可扩展性和资源需求方面都是独特的，通常有不同的权衡。重要的是拥有良好的基准来了解性能和可扩展性特征。

## Measuring Performance 性能评估

性能通常是最简单的评估特征，通常是指执行特定操作所需的时间。例如，可以构建基准来评估特定查询或查询类别的性能。

基准测试通常涉及多次执行查询并测量运行时间。

## Measuring Scalability 可扩展性评估

可扩展性是一个很宽泛的术语，有许多不同方面的可扩展性。术语上的可扩展性通常指性能如何随着影响性能的某些变量的值不同而变化。

一个例子是当请求 10GB、100GB 或者 1TB 数据时对性能的影响，随着总数据大小的增加而评估可扩展性。一个常见的目标是使之呈现线性可扩展性，这意味着查询 100GB 数据的时间应该是查询 10GB 数据时间的 10 倍。线性可扩展性让使用者更容易推断预期的行为。

其它影响性能的变量示例如下：

- 并发用户、请求或查询的数量
- 数据分区数
- 物理硬盘数量
- 核心数量
- 节点数量
- 可用内存
- 硬件类型（例如，树莓派和台式机）

## Concurrency 并发性

在基于并发请求数量评估可扩展性时，我们通常对吞吐量更感兴趣（每段时间内执行的查询总数），而不是单个查询的持续时间，尽管我们通常也会收集这些信息。

## Automation 自动化

运行基准测试通常非常耗时，因此自动化是必不可少的，这样可以进程运行基准测试，可能是每天一次，也可能是每周一次，这样就可以及早发现任何性能退化。

自动化对于保证基准测试的执行一致性以及收集和分析结果时可能需要的所有相关细节也很重要。

下面是执行基准测试时应该收集的数据类型示例：

### Hardware Configuration 硬件配置

- 硬件类型
- CPU 核心数量
- 可用内存和硬盘空间
- 操作系统名称和版本

### Environment 环境

- 环境变量（小心，不要泄露机要）

### Benchmark Configuration 基准测试配置

- 使用的基准测试软件版本
- 被测软件的版本
- 任何配置参数或文件
- 查询的所有数据文件的文件名
- 数据文件大小和校验和
- 已执行查询的详细信息

### 基准测试结果

- 基准测试开始的日期/时间
- 每次请求的起止时间
- 任何失败查询的错误信息

## Comparing Benchmarks 比较基准测试

比较不同版本之间的基准测试是很重要的，这样性能特征的变化就很明显，可以进一步研究。基准测试产生的大量数据通常很难手动比较，因此构建工具来协助完成此事或有裨益。

工具不是直接比较两组性能数据，而是数据的 “差异”，并显示同一基准的两次或多次运行之间的性能百分比差异。能够生成显示多个基准测试运行的图标也很有用。

## Publishing Benchmark Results 发布基准测试结果

下面是一些真实基准测试结果的示例，将 Ballista 中 Rust 和 JVM 执行器方案与 Apache Spark 的查询执行时间进行比较。尽管从这些数据中可以清楚地看到 Rust 执行器表现良好，但通过生成图标可以更好的表达这一点。

|CPU 核心数|Ballista Rust|Ballista JVM|Apache Spark|
|:-|:-|:-|:-|
|3|21.431|51.143|56.557|
|6|9.855|26.002|30.184|
|9|6.51|24.435|26.401|
|12|5.435|17.529|18.281|

与其绘制查询执行时间的图标，不如绘制吞吐量的图表。吞吐量（以每分钟查询数为单位）可以通过将 60 秒除以执行时间来计算。如果在单个线程上执行一个查询要 5 秒，那么每分钟应该可以运行 12 个查询。

下面是一个示例图表，显示了随着 CPU 内核数量的增加，吞吐量的可扩展性。

![benchmark](https://howqueryengineswork.com/resources/bench-desktop-0.2.5-SNAPSHOT.svg)

## Transaction Processing Council (TPC) Benchmarks 事务处理性能委员会基准

> [https://www.tpc.org/information/benchmarks5.asp](https://www.tpc.org/information/benchmarks5.asp)

事务处理委员会是一个数据库供应商的联盟，他们协作创建和维护各种数据库基准套件，以便在供应商的系统之间进行公平的比较。目前 TPC 的成员公司包括微软、甲骨文、IBM、惠普企业、AMD、英特尔和英伟达。

第一个基准是 TPC-A，于 1989 年发布，此后又创建了其它基准。TPC-C 是一个知名的 OLTP (OnLine Transaction Processsing 联机事务处理) 基准，常用于比较传统 RDBMS 数据库。而 TPC-H (已停止维护) 和 TPC-DS 通常用于测量 "大数据" 查询引擎的性能。

TPC 基准被视为业界的 “黄金标准”，但完全实施起来既复杂又费时。此外，这些基准的结果只能由 TPC 成员发布，并且只有在 TPC 对基准进行审计后才能发布。以 TPC-DS 为例，在撰写本文时，发布官方成绩的公司只有阿里巴巴、H2C、超微和 Databricks。

虽然如此，但 TPC 有一项合理使用政策，允许非成员基于 TPC 基准创建非官方的基准，只要遵守某些条件，比如在使用术语 TPC 之前加上 “源自 TPC”——“源自于 TPC-DS Query 14 的查询性能基准”。也必须维护 TPC 的版权声明和许可协议。可以发布的指标类型也有限制。

许多开源项目只是测量从 TPC 基准套件中执行单个查询的时间，并将其作为跟踪性能的一种方式，并与其它查询引擎进行比较。
